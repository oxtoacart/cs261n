\documentclass[conference]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{array}
\usepackage{graphicx}
\usepackage{url}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{textcomp}

% Avoid line breaks in program names.
\def\meekclient{\mbox{meek-client}}
\def\meekserver{\mbox{meek-server}}
\def\meek{meek}
\def\urll#1{\begin{NoHyper}\url{#1}\end{NoHyper}}

% https://tex.stackexchange.com/questions/113338/use-sans-serif-in-a-verbatim-environment/113339#113339
\makeatletter
\def\verbatim@font{\usefont{U}{cmtt}{m}{n}}
\makeatother

\begin{document}

\title{Blocking-resistant communication\\through domain fronting}

\author{David Fifield, Chang Lan}
\author{
\IEEEauthorblockN{David Fifield and Chang Lan}
\IEEEauthorblockA{University of California, Berkeley}
}

\maketitle

\begin{abstract}
We describe ``domain fronting,'' an application-layer technique
for HTTPS
that hides the remote endpoint of a communication
for the purpose of censorship circumvention.
Fronting enables a communication stream that is apparently with an allowed domain,
but actually with a forbidden domain.
The technique uses different domain names at different communication layers.
One domain is used on the ``outside''---in the DNS request and
TLS Server Name Indication---while another is used
on the ``inside''---the HTTP Host header, invisible to the
censor under HTTPS encryption.
We identify a number of hard-to-block web services,
like content delivery networks and Google's infrastructure,
that ignore the outside of an HTTPS request
and dispatch it internally according to the Host header.
The effect is that a user may communicate with any domain within the web service,
while appearing to communicate with any other domain.
If a censor is unable otherwise to distinguish fronted and non-fronted traffic,
then blocking circumvention traffic means blocking the whole web service,
with resulting expensive collateral damage.

We have implemented domain fronting in a system called \meek,
a pluggable transport for Tor.
\meek\ combines fronting with a proxy server that encodes a TCP stream
as a sequence of HTTP requests and responses.
The \meek\ server's external interface is that of an ordinary web server.
Communication with it is enabled through domain fronting.
The server receives requests, decodes them, and feeds their payloads into a Tor relay,
and returns downstream data in the HTTP response.
A censor watching the communication sees only a sequence of HTTPS requests to an allowed domain.
but which actually arrive at a special web server on a Tor relay.
\meek, or something based on it,
has been adopted by other circumvention systems including Lantern and Psiphon.

Hiding the endpoint and obscuring byte patterns are important parts of blocking-resistant communication,
but there are other, more subtle considerations.
We describe what we have done to disguise other traffic ``tells'' in \meek,
such as using a real web browser to make HTTPS requests
for a believable TLS fingerprint.
We argue that these measures increase the censor's effort
beyond simple one-shot techniques such as IP address blocking, and into
the realm of more expensive, less reliable statistical tests.
\end{abstract}

\section{Introduction}

% VPN arms race We seek to build a system that remains difficult to block even
% after it has many users.

Censorship is a daily reality for many Internet users.
Workplaces, schools, and governments use technical and social means
to prevent access to information by the network users under their control.
In response, those users use technical and social means
to gain access to the forbidden information.
What has emerged is an ongoing conflict between censor and censored,
with advances on both sides, more subtle evasion being countered by more powerful detection.

What we as circumventors have in our favor is the censor's
distaste for ``collateral damage,''
accidental overblocking committed in the course of trying to censor something else.
One way to win against the censor is to entangle circumvention traffic
with ordinary Internet traffic in a way that both must be blocked together
or not at all.
If the ordinary traffic is important enough,
above the censor's tolerance for overblocking,
then the circumvention traffic will get through.

In this paper we describe ``domain fronting,'' a general-purpose technique
based on HTTPS that hides the true destination of a communication
from a censor.
Fronting works with many web services that host multiple domain names
behind an HTTPS frontend server.
These include such high--collateral damage infrastructure as
big content delivery networks (CDNs)
and Google's panoply of services---a nontrivial fraction of the web.
See Section~\ref{sec:survey} for a listing of some suitable services.
Domain fronting can be used as a means of tunneling traffic
to a general-purpose proxy,
so it is not limited to HTTPS, nor to the domains of any specific web service.

The key idea of domain fronting is using
different domain names at different layers of communication.
In an HTTPS request, the destination domain name appears
in three places relevant to the discussion:
the DNS query,
the TLS Server Name Indication (SNI) extension~\cite[Section~3]{rfc6066},
and the HTTP Host header~\cite[Section~14.23]{rfc2616}.
Normally, the same domain name appears in all three places.
In a domain-fronted request,
the DNS query and SNI carry one name (the ``front domain''),
while the HTTP Host header,
which is hidden from censor by HTTPS encryption,
has a different name (the actual destination).

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{fronting}
\caption{
Domain fronting uses different domain names at different layers of communication.
At the plaintext layers visible to the censor---the DNS request and the
TLS Server Name Indication---appears
the front domain \mbox{\textbf{allowed.example}}.
At the HTTP layer, unreadable to the censor but meaningful to the CDN or web service,
is the actual destination \mbox{\textbf{forbidden.example}}.
}
\label{fig:fronting}
\end{figure}

Neither the DNS nor the SNI can be blocked without
collaterally blocking the front domain.
The Host header is unknown to the censor,
but known to the server receiving the HTTPS request,
which uses the header to internally route the request to its destination.
No traffic ever reaches the front domain,
which may be oblivious to the circumvention.
For those familiar with decoy routing~\cite{decoyrouting,telex,cirripede,tapdance},
domain fronting can be understood as
``decoy routing at the application layer.''
A fuller comparison with decoy routing appears in Section~\ref{sec:related-work}.

A Wget command shows domain fronting in action
on Google's infrastructure.
An HTTPS request for \urll{www.google.com} has a Host header for
\urll{maps.google.com}, and the HTML in the response is that of Google Maps.

\noindent
\begin{quote}
\usefont{U}{cmtt}{m}{n}%
\$ wget -q -O - https://www.google.com/ \char`\\\\
\strut~~~~--header \textquotesingle{}Host: maps.google.com\textquotesingle{} | \char`\\\\
\strut~~~~grep -o \textquotesingle{}<title>.*</title>\textquotesingle{}\\
<title>Google Maps</title>
\end{quote}

Domain fronting works with CDNs because a CDN's frontend server
(called an ``edge server''),
on receiving a request for a resource not already cached,
forwards the request to the domain in the Host header
(the ``origin server'').
(There are other ways for CDNs to work, but this ``origin pull''
configuration is common.)
% The certificate you get may be that of the front domain,
% or may be a generic shared domain.~\cite{httpsincdn}
The CDN's edge server won't forward requests just anywhere---it
has to be to the domain of a customer.
This means that in order to host a proxy,
one has to create an account and pay for bandwidth.
Fronting works with Google because Google App Engine, a web application platform,
can host a simple ``reflector'' application that emulates
an origin-pull CDN, simply forwarding every request to an origin server.

A variation on fronting is ``domainless'' fronting,
in which there is no DNS request and no SNI extension.
It looks to the censor
like the user is browsing an HTTPS site by its IP address,
or using an old browser that doesn't support SNI.
Domainless fronting can be useful when there is no front domain
with sufficiently high collateral damage.
The censor is faced with the choice of blocking an entire IP address,
blocking requests without SNI,
or finding some other, presumably more expensive, test to distinguish
circumvention traffic.

We have developed domain fronting into a full-fledged circumvention system called \meek,
implemented as a Tor pluggable transport~\cite{pt}.
\meek\ combines fronting with an HTTP-based tunneling proxy:
upstream data are transformed into a sequence of HTTP requests,
which are fronted in order to reach a proxy server.
The server decodes the requests and feeds their payloads
into a local Tor relay.
Downstream data received from the Tor relay
are returned to the client as HTTP responses
through the same fronted channel.
\meek's architecture appears in Figure~\ref{fig:architecture}.
Section~\ref{sec:architecture} describes its workings in detail.

\begin{figure*}
\centering
\includegraphics[width=\linewidth]{architecture}
\caption{
Architecture of \meek.
The client sends an HTTP request to the Tor bridge by way of an intermediate web service such as a CDN.
The client protects the bridge's domain name \textbf{forbidden.example} from the censor
by fronting it with another name, here \textbf{allowed.example}.
The intermediate web server decrypts the TLS layer and forwards the request to the bridge
according to the Host header.
The bridge sends data back to the client in the HTTP response.
\meekclient\ and \meekserver\ are transport plugins, the interface between Tor and \meek.
The host actually at allowed.example does not participate in the communication.
}
\label{fig:architecture}
\end{figure*}

\meek\ has been built into an alpha version of Tor Browser,
and has seen use by a small number of users.
Our deployment uses Google App Engine,
with the hidden actual domain \urll{meek-reflect.appspot.com}
hidden by the front \urll{www.google.com}.
Section~\ref{sec:deployment} discusses other systems \meek\ can work with
and other deployment scenarios.
In addition to the Tor pluggable transport,
systems based on \meek\ are now in use by other circumvention systems
including Psiphon~\cite{psiphon} and Lantern~\cite{lantern}.

% \meek\ is designed to have features attractive in a circumvention transport.
% It is easy to use, not requiring the configuration of any bridge addresses.
% In Tor Browser, users need only select ``meek''
% from a pulldown menu in order to use it.
% It resists blocking by address and by content,
% Section~\ref{sec:discussion}

Domain fronting and HTTPS take care of two big circumvention challenges,
namely hiding the destination and obscuring the contents of the message.
There remain other, more subtle, meta-attributes of communication
that could serve as a basis for blocking.
For example, the handshake is a fingerprintable part of TLS.
Section~\ref{sec:browserextension} describes how we use a web browser extension as an instrument for making HTTPS requests,
in order that \meek's TLS and HTTPS characteristics
match those of a browser as closely as possible.
One of our goals for \meek\ is to force the censor
to employ more sophisticated, expensive, and error-prone statistical tests
to classify traffic as allowed or prohibited,
rather than simple domain blacklists or deep packet inspection;
to force the frontier of censorship
to be a frontier not of simple in-line packet filters,
but of probabilities and false positives.
A preliminary analysis of \meek's resistance to detection
based on traffic characteristics like packet size and timing
appears in Section~\ref{sec:trafficanalysis}.
The analysis is based on comparing traffic traces of \meek
with samples of HTTPS traffic at an Internet router.

To our knowledge,
the earliest application of domain fronting to circumvention
was by GoAgent~\cite{goagent},
a tool based on App Engine and
once widely used in China.
Fronting has also been used with success since 2013
for the rendezvous component of another transport called flash proxy~\cite{flashproxy}.
GoAgent and flash proxy's rendezvous are the most direct
inspirations of this work.

% We measure the performance...

\section{Background and related work}
\label{sec:related-work}

Broadly speaking, there are two main challenges in circumvention:
blocking by content and blocking by address.
Blocking by content is based on \emph{what you say},
and blocking by address is based on \emph{whom you talk to}.
A content-blocking censor inspects packets and payloads,
looking, for example, for forbidden protocols or keywords.
Content-based blocking is sometimes called deep packet inspection (DPI).
An address-blocking censor forbids all communication with certain
addresses, for example IP addresses and domain names, whatever the contents may be.
A savvy censor will use both means of censorship---therefore
effective circumvention requires countering both.

To the above challenges we may add a related one, active probing.
An active-probing censor does not merely passively observe traffic;
it injects its own traffic,
acting as if it were an ordinary client and connecting to suspected
proxy servers to see how they respond.
If the connection is successful, the server can then be blacklisted.
Active probing is a precise means of identifying a server as belonging to a circumvention system,
even when a protocol is hard to classify on the wire.
Winter and Lindskog~\cite{foci12-winter} confirmed an earlier discovery of
Wilde~\cite{wilde} that China's Great Firewall identifies Tor bridges
by issuing followup scans to observed client connections to see
whether a server speaks the Tor protocol.
The discovery of active probing was the motivation for probing resistance in ScrambleSuit~\cite{scramblesuit}
and obfs4~\cite{obfs4},


There are two general strategies for countering DPI.
The first is to make traffic look unlike
anything forbidden by the censor; that is, fail to match a blacklist. The second is
to resemble a protocol that is explicitly allowed by the censor; that is, match a whitelist.
Following the first strategy are the ``look-like-nothing'' transports whose
payloads are indistinguishable from a uniformly random byte stream.
Well-traveled look-like-nothing
protocols are obfs2~\cite{obfs2} and its successor obfs3~\cite{obfs3},
which have been Tor's go-to pluggable transports since early 2012~\cite{obfsproxy-arms-race}.
They both work by superenciphering a stream, using a key exchange that has no plaintext components.
ScrambleSuit~\cite{scramblesuit} is like obfs3 in the
content of its payloads, but additionally obscures its traffic signature
(packet lengths and timing), and is designed to resist active probing.
A ScrambleSuit server will accept a TCP connection but not send anything
until the client proves knowledge of shared secret, depriving the censor
of an easy distinguisher.
obfs4~\cite{obfs4}
(which despite the name has more in common with ScrambleSuit than with obfs2 and obfs3)
builds on ScrambleSuit with more efficient cryptography and an authenticated handshake.

The other strategy against DPI is the steganographic approach: look like
something the censor doesn't block.
fteproxy~\cite{fte} uses format-transforming encryption to encode data into strings
that match a given regular expression,
for example a regular-expression approximation of HTTP,
in order to match a firewall's whitelist.
StegoTorus~\cite{stegotorus}
encodes traffic to look like a cover protocol
using a variety of special-purpose encoders.
Code Talker
Tunnel (formerly called SkypeMorph)~\cite{skypemorph} mimics a Skype video call.
FreeWave~\cite{freewave} encodes a stream as an acoustic signal
and sends it over VoIP to a proxy, which decodes it and forwards it to the destination.
Dust~\cite{dust} uses encryption to hide static byte patterns and then
shapes statistical features such as packet lengths and byte frequencies so that they
match given distributions.

Houmansadr et~al.~\cite{parrot} evaluate ``parrot'' systems that imitate another protocol
and conclude that unobservability by imitation is fundamentally flawed.
To fully mimic a complex and sometimes proprietary protocol like Skype
is difficult,
because the system must imitate not only the normal operation of the protocol,
but also its reaction to errors,
its typical traffic patterns, and quirks of implementations.
Geddes et~al.~\cite{acks}
demonstrate that even non-parrot systems may be vulnerable to
attacks that disrupt circumvention while having little effect
on ordinary traffic.
Their examination includes VoIP protocols,
in which packet loss and duplication are acceptable.
The censor may, for example, strategically drop certain packets
in order to disrupt a covert channel, without much harming ordinary VoIP calls.


The other grand challenge of proxy-based circumvention is address-based blocking.
Tor has long faced the blocking of its entry relays,
the addresses of which are in a public directory.
In response, Tor began to reserve a portion of its
new relays as secret ``bridges''~\cite{tor-blocking}
whose addresses are not publicly known.
BridgeDB, the database of secret bridges,
carefully distributes bridge addresses
so that anyone can learn a few bridges, but it is hard to learn all of them.
BridgeDB uses captchas and other rate-limiting measures,
and over short time periods,
always returns the same set of bridges to the same requester,
preventing enumeration by simple repeated querying.
BridgeDB is also capable of distributing the addresses
of obfuscated bridges (obfs3 or ScrambleSuit);
the combination
of careful bridge address dispersal and obfuscated protocols
gives Tor's system a realistic claim to addressing both main challenges of circumvention.
Address distribution appears to be the weaker side of the defense,
as evidenced by real-world censors' apparent preference for
blocking bridge addresses over real-time DPI-based blocking~\cite{foci12-winter}.

Flash proxy~\cite{flashproxy} resists address blocking by
conscripting web users as temporary proxies. Proxies last only as long as a web
user stays on a page, so the pool of proxies is constantly changing.
If one of them is blocked, there is soon another to replace it.
Flash proxy's approach to address blocking is in a sense
the opposite of \meek's:
where flash proxy uses many cheap, disposable, individually blockable proxies,
\meek\ uses just a few high-value front domains on hard-to-block network infrastructure.
A quirk of the browser proxy model is that
the client must be able to receive a TCP connection; in particular it
must not be behind network address translation~(NAT), which limits flash proxy's usefulness.
Part of the flash proxy protocol requires the client to send
a small amount of unblockable data in a process called rendezvous.
The default rendezvous mechanism has used domain fronting through App Engine since 2013~\cite{flashproxy-reg-appspot}.
Flash proxy itself does nothing to defend against DPI.
Connections between censored clients and browser-based proxies use
WebSocket, a meta-protocol running on HTTP,
but inside the WebSocket framing is the ordinary Tor protocol.
% There exists a prototype transport that attempts to get both
% content-based and address-based blocking resistance by obfuscating traffic
% with obfsproxy before sending it through flash proxy~\cite{obfs-flash}.
% However it is limited because it is not
% possible to obfuscate the outermost WebSocket layer;
% the censor could decide simply to block all WebSocket.

A technique known as OSS~\cite{oss} (for
``online scanning service'') bounces messages
through web services that are capable of making HTTP requests.
For example, a censored client may ask an HTTPS-based online translation service to
translate the web page at \urll{http://forbidden.example/}\textsl{data...},
where ``\textsl{data...}'' is the message the client wishes to send,
embedded in the URL.
The translation service requests the URL,
unwittingly sending the message on behalf of the client.
OSS shares certain similarities with domain fronting:
the web service takes the place of the front domain,
and the destination of the communication is embedded somewhere in an HTTPS query
rather than in the Host header.

Decoy routing~\cite{decoyrouting}, also called end-to-middle proxying,
is a technique that puts
proxies in the middle of network paths, rather than at the ends.
Realizations of decoy routing include Telex~\cite{telex},
Cirripede~\cite{cirripede}, and TapDance~\cite{tapdance}.
Decoy routing asks friendly ISPs to deploy special routers that lie
on network paths between censored users and uncensored ``decoy'' Internet destinations.
Circumvention traffic is ``tagged'' in a way that is detectable only
by the special routers, and not by the censor.
On receiving a tagged communication, the router shunts it away from its apparent, \emph{overt destination}
and toward a censored, \emph{covert destination}.
Domain fronting is similar in spirit to decoy routing;
think of domain fronting as decoy routing at the application layer.
In place of a router, domain fronting has a web service's frontend server;
in place of the overt destination is the front domain.
Both systems tag flows in a way that is invisible to the censor:
decoy routing uses, for example, a hash embedded in a client nonce,
while fronting uses the HTTP Host header, encrypted within HTTPS.
Fronting has the advantage that it doesn't require knowing cooperation by network intermediaries.

Schuhard et~al.~\cite{ccs2012-decoys}
introduce the idea of a \emph{routing adversary} against decoy routing,
and show that the connectivity of the Internet enables
censors to force network users onto paths that do not include participating routers.
Simulations by Houmansadr et~al.~\cite{nodirectionhome}
show that even though such alternate paths exist,
they are many times more costly to the censor,
especially when participating routers are placed strategically.

CensorSpoofer~\cite{censorspoofer}
decouples upstream and downstream data channels.
The client sends data to a CensorSpoofer proxy over a low-bandwidth covert channel such as email.
The proxy sends data back over a UDP channel, all the time
spoofing its source address so the packets appear to originate from some other ``dummy'' host.
The censor has no IP address to block, because the proxy's true address never appears on the wire.
Client and server have the challenge of agreeing on a dependable covert upstream channel
that must itself remain unblocked,
and the client must carry on a believable UDP conversation with the dummy host
(the authors suggest a VoIP call).

CloudTransport~\cite{cloudtransport} uses cloud storage, for example Amazon~S3,
as a communication channel by encoding sends and receives as reads and writes to shared remote files.
CloudTransport has much in common with domain fronting:
it hides the true endpoint of a communication with HTTPS,
and sends traffic through a domain with high collateral damage.
In CloudTransport, the hidden destination, which is a storage bucket name rather than a domain,
is hidden in the path rather than the Host header.
For example, in an example S3 URL
\urll{https://s3.amazonaws.com/bucketname/filename},
the censor only gets to ``see'' the generic domain part, \urll{s3.amazonaws.com}.
The path component \urll{/bucketname/filename},
which would reveal that CloudTransport is being used,
cannot be used for blocking because it is encrypted in HTTPS.

GoAgent~\cite{goagent} is a direct inspiration for \meek\ in its use of App
Engine and Host header--based domain fronting.
Traffic is fronted by the Google frontend server
and delivered to its destination by a specialized app running on App Engine.
GoAgent uses the ``domainless'' fronting model without SNI for most target domains.
GoAgent doesn't use an additional general-purpose proxy after fronting;
rather, HTTP and HTTPS URLs are fetched directly from the App Engine servers,
meaning that GoAgent is limited to carrying HTTP and HTTPS traffic,
and the contents of all communications are revealed to App Engine.
Users of GoAgent upload their own personal copy of the proxy code to App Engine,
which is free of charge as long as they do not exceed a bandwidth quota.
According to a May 2013 survey~\cite{collateral-freedom},
GoAgent was the circumvention tool most used in
China, with 35\% of survey respondents having used it in the previous month.
This figure is higher than that of paid~(29\%) and free VPNs~(18\%), and far
above that of other special-purpose tools like Tor~(2.9\%) and Psiphon~(2.5\%).
Use of GoAgent in China was disrupted starting in the beginning of June~2014
when all Google services (including GoAgent's front domains) were blocked~\cite{cn-google-block}.
\meek\ over App Engine was similarly affected.
% Users identified reliability, speed, and ease of installation as the most important features of a circumvention tool.

Cloud-Entry~\cite{cloud-entry} is somewhat similar to GoAgent.
It also uses App Engine, but uses a socket API rather than a URL fetch API
in order to support protocols other than HTTP and HTTPS.
Cloud-Entry has the same problem with NAT that flash proxy does,
because the proxy tries to connect back to the client with a socket.
App Engine kills web requests (and their associated socket connections)
that take longer than 60~seconds,
so users must reconnect at least every 60~seconds.

Psiphon~\cite{psiphon} is a network of many one-hop proxies,
with encryption and traffic obfuscation between client and server.
Psiphon uses domain fronting based on \meek\ as one of its blocking defenses since June~2014~\cite{psiphon-meek-merge}.
Lantern~\cite{lantern} uses a network of proxies running on volunteer computers;
proxy addresses are shared only with trusted friends in order to make them difficult to enumerate.
Lantern~1.4 is planned to use domain fronting inspired by \meek~\cite{lantern-1.3.1}.

% Infranet
% Freegate
% Ultrasurf

% CORDON? Say how \meek\ would be classified in it?

% Section~\ref{sec:browserextension}, JumpBox
% http://securecomm.org/2014/show/tutorials

\section{Threat model}

The model includes four actors:
the censor,
the censored client,
the intermediate web service (CDN),
and the destination Tor bridge.
Circumvention is achieved when the client evades the censor to reach
the bridge,
because the bridge proxies to anywhere.
The client and bridge cooperate with each other.
The intermediate web service does not cooperate with either,
except to the extent that it doesn't collude with the censor.
% The censor's goal is to prevent circumvention.

The censor controls a network and the into and within it.
The censor is able to inspect traffic flowing across all links under its control
and may block or allow any packet.
The censor may inject and replay traffic, and
operate its own clients and servers.
The client lies within the censor's network,
while the intermediate web service and bridge lie outside the network.
The censor blocks direct communication between the client and the bridge,
but allows HTTPS between the client and at least one front domain or IP address
on the intermediate web service.
% In examples, we will use the \textbf{allowed.example} as the front domain
% and \textbf{forbidden.example} as the domain name of the Tor bridge.

% The censor must operate at line rate; that is,
% it must not delay traffic unduly while deciding whether to allow it.
% This consideration is one facet of the censor's sensitivity to
% collateral damage caused by false positives:
% mistakenly blocking or degrading non-circumvention traffic causes the censor
% to incur some penalty, just as mistakenly allowing circumvention traffic does.

The client,
intermediate web service,
and destination proxy
are uncontrolled by the censor.
The censor does not control a TLS certificate authority;
specifically it cannot man-in-the-middle an HTTPS session
without being caught by ordinary certificate verification.
The client has a way to get a copy of the necessary client programs.

Section~\ref{sec:discussion} shows what happens when some
of these assumptions are violated;
specifically what happens
when the intermediate web service's frontend server is inside the censor's network
and when the censor controls a certificate authority.
That section also describes the use of \meek\ apart from Tor.

% What about in-country edge servers; seems to work.

\section{Architecture and protocol of \meek}
\label{sec:architecture}

The components of the system are shown in Figure~\ref{fig:architecture}.
The parts that are new in \meek
are the programs \meekclient\ and \meekserver,
which are the pluggable-transports~\cite{pt} interface between Tor and \meek.
% All the programs are free software, naturally,
% and may be downloaded from the \meek\ home page at
% \url{https://trac.torproject.org/projects/tor/wiki/doc/meek}.

\meekclient\ is essentially a web client that knows how to front HTTPS requests.
When \meekclient\ receives data from a client Tor process, it bundles it up into a POST request
and fronts the request through the web service
(which in turn forwards it to \meekserver\ on the bridge).
If the response contains any payload, \meekclient\ decodes it and returns it back to Tor.
\meekclient\ takes pains to make its TLS fingerprint
look like that of a browser; see Section~\ref{sec:browserextension}.

\meekserver\ is a special-purpose web server.
When \meekserver\ receives a request, it extracts the body and feeds it into
a local Tor running as a bridge.
If there are any data pending to be sent back to the client from Tor,
\meekserver\ includes it in the body of the HTTP response.
\meekserver\ also handles session management:
as there may be many clients using the service at once,
the server must determine which client session each incoming request belongs to.
% It does this by means of an X-Session-Id header,
% described in this section.

When \meek\ is used with Google App Engine, one other component is needed.
It is a small ``reflector'' web app that simply copies any request
it receives and forwards it to an instance of \meekserver\ running on a bridge.
App Engine cannot directly run a Tor bridge,
so we bounce the requests to somewhere that can.
The reflector app emulates the behavior of an origin-pull CDN,
which also simply copies and forwards a request to the origin server
when the response is not already cached.

The main technical challenge is handling a TCP stream
that has been split up into a sequence of HTTP requests and responses.
The body of each HTTP request and HTTP response carries
a small chunk of upstream or downstream communication.
\meekserver\ must handle many clients at once,
and therefore maintains many open connections to the local Tor process,
one for each active client.
When a new request arrives, the server must determine which
open session it belongs to
(or whether it is a brand-new client needing a new session).
In TCP, different streams are distinguished by their
(source~IP, source port, dest~IP, dest~port) tuple,
but that doesn't work for \meek\ for two reasons:
the source IP of the requests is that of the intermediate web service,
not that of the client;
and a logical stream is chopped into multiple independent HTTP requests,
so the source port is always changing.
Rather, each client generates a random 256-bit session ID,
which it sends with each of its requests in a special
X-Session-Id header.
\meekserver, when it sees a session ID for the first time,
opens up a new connection to the local Tor process
and associates the connection and ID in a cache.
Subsequent requests with the
same session ID will reuse the same Tor connection.
Sessions are closed after a period of inactivity.
Figure~\ref{fig:protocol} shows a sample of the protocol.

\begin{figure}
\scriptsize
\begin{verbatim}
POST / HTTP/1.1
Host: forbidden.example
X-Session-Id: cbIzfhx1Hn+RHURmIPhjgY+W3B6zA8Ua6dd92DLscOE=
Content-Length: 517

\x16\x03\x01\x02\x00\x01\x00\x01\xfc\x03\x03\x9b\xa9\x9f...
\end{verbatim}
\smallskip
\begin{quote}
\begin{verbatim}
HTTP/1.1 200 OK
Content-Length: 739

\x16\x03\x03\x00\x3e\x02\x00\x00\x3a\x03\x03\x53\x75\xa2...
\end{verbatim}
\end{quote}
\smallskip
\begin{verbatim}
POST / HTTP/1.1
Host: forbidden.example
X-Session-Id: cbIzfhx1Hn+RHURmIPhjgY+W3B6zA8Ua6dd92DLscOE=
Content-Length: 0

\end{verbatim}
\smallskip
\begin{quote}
\begin{verbatim}
HTTP/1.1 200 OK
Content-Length: 75

\x14\x03\x03\x00\x01\x01\x16\x03\x03\x00\x40\x06\x84\x25...
\end{verbatim}
\end{quote}
\caption{
Requests and responses in the \meek\ HTTP protocol.
The session ID is randomly generated by the client.
Request/response bodies contain successive chunks of a Tor TLS stream
(\texttt{\textbackslash{}x16\textbackslash{}x03\textbackslash{}x01\textbackslash{}x02}
is the beginning of a TLS ClientHello message).
The second POST request is an empty polling request.
The messages shown here is encrypted inside HTTPS until after
it has been fronted,
so the censor cannot use the
Host and X-Session-Id headers for classification.
}
\label{fig:protocol}
\end{figure}

The underlying TCP stream is broken into chunks so that
There must therefore be some way of making sure that chunks
are correctly reassembled at the other end,
in order and without gaps and duplicates.
\meek\ takes a naive approach: requests and responses are strictly serialized.
The client doesn't send a second chunk of data
(i.e, make another HTTPS request) until it has
receive the response to the first request.
The underlying stream is simply the concatenation
of chunks in the order they arrive.
Doing it this way is simple and guarantees correctness,
but has performance drawbacks because there is a full round-trip
between every send.
The performance drawbacks are not inherent to the design:
it is domain fronting, not HTTP encoding, that is the fundamental strength of the system.
Section~\ref{sec:futurework} describes more efficient encodings
that enable multiple requests in parallel.

HTTP is fundamentally a request-based protocol.
There is no way for the server to ``push'' data to the client without
having first received a request.
In order to enable the server to send back data,
\meek\ uses one of two techniques.
The first is polling:
every so often the client sends a request with an empty payload
if it has nothing else to send.
The polling interval starts short (100~ms) and grows exponentially
up to a maximum of 5~s.
% Implemented in Psiphon's version.
The other technique,
implemented in Psiphon's version of \meek,
uses long-lived persistent HTTP connections.
When the server sends a response, it keeps the connection open,
continually appending data to the response body while it has anything to send.
When the server receives a new request from the same client,
it closes any response it has open to the client and starts a new response.
This second technique doesn't work on all services:
notably Google App Engine doesn't support streaming downloads of this kind.

\section{Camouflage for the TLS layer}
\label{sec:browserextension}

Domain fronting defeats address-based blocking and active probing.
HTTPS foils the most straightforward DPI,
hiding byte patterns in the underlying stream.
The censor may try to apply more careful DPI in order to
distinguish fronted and non-fronted traffic.
This section is about TLS fingerprinting,
which is the censor's remaining easy distinguisher,
and how we use a web browser with an unremarkable TLS fingerprint
to disguise the HTTPS tunnel.
Section~\ref{sec:trafficanalysis} is about more subtle and hard-to-apply forms of DPI.

The TLS handshake is largely plaintext~\cite[Section~7.4]{rfc5246}.
The plaintext SNI extension, for instance, has to be protected by domain fronting.
There is enough room for variation in other fields,
such as the client's lists of ciphersuites and extensions,
that it is possible to fingerprint different client TLS implementations~\cite{ssl-p0f}.
(We are only concerned with fingerprinting the client,
because the server's TLS that the censor can observe
comes from the intermediate web service;
i.e., it is what you would expect when connecting to the front domain.)
Tor itself was blocked by China in 2011
because of the distinctive ciphersuite list it used at that time~\cite{bug4744}.

Figure~\ref{fig:ciphersuites} shows examples of how TLS client
implementations may differ.
\meekclient\ is written in the Go programming language,
which has a custom TLS library~\cite{golang-crypto/tls};
Figure~\ref{fig:ciphersuites:golang}
shows how it would appear with no TLS camouflage.
Figures~\ref{fig:ciphersuites:firefox} and~\ref{fig:ciphersuites:chrome},
which are browsers, are different; the browsers are also unlike each other.
A censor could block an uncamouflaged \meek\ using Go's fingerprint,
if it considered the collateral damage resulting from blocking other Go programs to be slight enough.

\begin{figure*}
\centering
\begin{subfigure}[t]{0.30\textwidth}
\caption{Go 1.2's net/http library}
\begin{minipage}[t][25.5ex][t]{\textwidth}
\tiny
\begin{verbatim}
Ciphersuites:
  TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
  TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
  TLS_ECDHE_RSA_WITH_RC4_128_SHA
  TLS_ECDHE_ECDSA_WITH_RC4_128_SHA
  TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
  TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA
  TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
  TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
  TLS_RSA_WITH_RC4_128_SHA
  TLS_RSA_WITH_AES_128_CBC_SHA
  TLS_RSA_WITH_AES_256_CBC_SHA
  TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA
  TLS_RSA_WITH_3DES_EDE_CBC_SHA
Extensions:
  server_name
  status_request
  elliptic_curves
  ec_point_formats
  signature_algorithms
\end{verbatim}
\end{minipage}
\label{fig:ciphersuites:golang}
\end{subfigure}
%
\begin{subfigure}[t]{0.30\textwidth}
\caption{Firefox 24}
\begin{minipage}[t][57ex][t]{\textwidth}
\tiny
\begin{verbatim}
Ciphersuites:
  TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
  TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA
  TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
  TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
  TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA
  TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA
  TLS_ECDHE_ECDSA_WITH_RC4_128_SHA
  TLS_ECDHE_RSA_WITH_RC4_128_SHA
  TLS_DHE_RSA_WITH_AES_128_CBC_SHA
  TLS_DHE_DSS_WITH_AES_128_CBC_SHA
  TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA
  TLS_DHE_DSS_WITH_CAMELLIA_128_CBC_SHA
  TLS_DHE_RSA_WITH_AES_256_CBC_SHA
  TLS_DHE_DSS_WITH_AES_256_CBC_SHA
  TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA
  TLS_DHE_DSS_WITH_CAMELLIA_256_CBC_SHA
  TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA
  TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA
  TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA
  TLS_ECDH_RSA_WITH_AES_128_CBC_SHA
  TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA
  TLS_ECDH_RSA_WITH_AES_256_CBC_SHA
  TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA
  TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA
  TLS_ECDH_ECDSA_WITH_RC4_128_SHA
  TLS_ECDH_RSA_WITH_RC4_128_SHA
  TLS_RSA_WITH_AES_128_CBC_SHA
  TLS_RSA_WITH_CAMELLIA_128_CBC_SHA
  TLS_RSA_WITH_AES_256_CBC_SHA
  TLS_RSA_WITH_CAMELLIA_256_CBC_SHA
  TLS_RSA_WITH_SEED_CBC_SHA
  SSL_RSA_FIPS_WITH_3DES_EDE_CBC_SHA
  TLS_RSA_WITH_3DES_EDE_CBC_SHA
  TLS_RSA_WITH_RC4_128_SHA
  TLS_RSA_WITH_RC4_128_MD5
Extensions:
  server_name
  renegotiation_info
  elliptic_curves
  ec_point_formats
  SessionTicket TLS
  next_protocol_negotiation
\end{verbatim}
\end{minipage}
\label{fig:ciphersuites:firefox}
\end{subfigure}
%
\begin{subfigure}[t]{0.30\textwidth}
\caption{Chrome 33}
\begin{minipage}[t][42.5ex][t]{\textwidth}
\tiny
\begin{verbatim}
Ciphersuites:
  TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
  TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
  TLS_DHE_RSA_WITH_AES_128_GCM_SHA256
  TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256
  TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
  TLS_RSA_WITH_AES_128_GCM_SHA256
  TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
  TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
  TLS_DHE_RSA_WITH_AES_256_CBC_SHA
  TLS_RSA_WITH_AES_256_CBC_SHA
  TLS_ECDHE_ECDSA_WITH_RC4_128_SHA
  TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA
  TLS_ECDHE_RSA_WITH_RC4_128_SHA
  TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
  TLS_DHE_RSA_WITH_AES_128_CBC_SHA
  TLS_DHE_DSS_WITH_AES_128_CBC_SHA
  TLS_RSA_WITH_RC4_128_SHA
  TLS_RSA_WITH_RC4_128_MD5
  TLS_RSA_WITH_AES_128_CBC_SHA
  TLS_RSA_WITH_3DES_EDE_CBC_SHA
Extensions:
  server_name
  renegotiation_info
  elliptic_curves
  ec_point_formats
  SessionTicket TLS
  next_protocol_negotiation
  application_layer_protocol_negotiation
  Channel ID
  status_request
  signature_algorithms
  Signed Certificate Timestamp
\end{verbatim}
\end{minipage}
\label{fig:ciphersuites:chrome}
\end{subfigure}

\caption{
Selected differences in ClientHello messages in three different TLS implementations.
}
\label{fig:ciphersuites}
\end{figure*}

In order to disguise its TLS fingerprint,
\meekclient\ proxies all its HTTPS requests through an actual web browser.
We implemented extensions for two web browsers,
Firefox and Chrome,
that enable them to make HTTPS requests on behalf of \meekclient.
The TLS fingerprint looks like that of a browser, because it is that of a browser.
The browser instance with the extension is completely separate
from the browser the user interacts with.
It runs invisibly in the background in a separate process,
doesn't display a user interface,
and shares no state with the user's browser.

\begin{figure}
\centering
\includegraphics[height=1.5in]{browser-architecture}
\caption{
Client architecture including a browser extension for TLS camouflage.
Dashed lines show the process hierarchy.
Solid lines show the flow of outgoing communication.
The headless browser runs in the background and is invisible to the user.
This figure is a zoomed-in view of the ``Client's PC'' component of Figure~\ref{fig:architecture}.
}
\label{fig:browser-architecture}
\end{figure}

Figure~\ref{fig:browser-architecture} shows the interaction of components
on the client's computer.
The local Tor process starts a helper process that starts both \meekclient\
and the headless browser,
then configures \meekclient\ to proxy its requests through the browser extension.
The user's browser proxies through Tor;
Tor proxies through \meekclient,
and \meekclient\ proxies through the headless browser.
The headless browser is the only thing that ever actually touches the network.
It should be emphasized that the URLs requested by the headless browser extension
have no relation to the URLs the user actually browses;
the extension only ever makes requests to the front domain.

The use of a browser extension brings benefits beyond TLS camouflage.
It means \meek\ inherits other traffic characteristics of the browser:
for instance
how often it resolves DNS names,
its connection reuse,
and its HTTP keepalive behavior.
The Firefox extension has special advantages
when \meek\ is used with Tor Browser
because Tor Browser
is a modified version of Firefox.
We can use the same browser executable for both the browser the user interacts with (Tor Browser)
and the one providing TLS camouflage (a headless Firefox),
saving space in distribution packages
and sparing the user from having to separately configure a browser to run the extension.
In Tor Browser,
the headless Firefox is started and stopped transparently
when \meek\ is activated and deactivated.

% The development of the browser extensions posed some unexpected challenges.
% Tor Browser disables TLS session tickets because they can be used as linking identifiers,
% but the lack of session tickets shows up as a missing TLS extension,
% so we had to reenable them in the headless browser.
% (Doing so doesn't harm Tor Browser's anonymity:
% if session tickets are used, they are used only on the circumvention layer
% between the user and the frontend server. Tor Browser's own TLS is tunneled
% within the circumvention layer, and session tickets are still disabled at that level.)
% The Chrome extension needed to be split into two pieces, an extension and an app,
% because an extension cannot open a listening socket and an app cannot make HTTP requests.

No TLS camouflage is needed between the intermediate web service and \meekserver,
because that portion of the communication flow is not observed by the censor.

Appropriate TLS camouflage may differ according to circumstances.
On a traditional desktop PC, using a browser is probably the right choice.
When Psiphon ported \meekclient\ to Android,
they didn't use a browser as camouflage,
but rather made all HTTPS requests with the standard Android HTTP API.
This decision makes sense because typical Android applications
also use the standard API and share the same TLS fingerprint.

\section{A survey of fronting-capable web services}
\label{sec:survey}

This section contains a brief survey of the fronting-capable
web services we have found, each with its pros and cons.
The list is not exhaustive and is meant to illustrate the broad
support that exists for fronting.
Of the services listed, we have deployed \meek
only on Google App Engine and Amazon CloudFront.
We have only checked that fronting works on the others.
Recall that even web services that support fronting
will front only for their own customers,
so each deployment typically requires an investment of time and money.

Google App Engine (\url{https://developers.google.com/appengine/})
is a web application platform.
Each application gets a subdomain of \urll{appspot.com},
which can be fronted through almost any Google domain,
including google.com, gmail.com, googleapis.com, and many others.
App Engine can run only web applications,
not a full Tor bridge;
for that reason we use a tiny ``reflector'' application
that merely copies incoming requests to a Tor bridge hosted elsewhere.
Fronting through App Engine is attractive in the case where
\urll{appspot.com} is blocked---not unlikely,
because of the ease of building a proxy there---but
at least one other Google service is reachable.
Applications that use less than one gigabyte of bandwidth daily
are free of charge,
making possible an upload-your-own-app model
Ã  la GoAgent.

Amazon CloudFront (\url{https://aws.amazon.com/cloudfront/}),
not to be confused with CloudFlare,
is the CDN of Amazon Web Services.
A CloudFront ``distribution'' associates
a randomly generated subdomain of \urll{cloudfront.net}
with an origin server,
which in our case is an instance of \meekserver.
The front domain may be any other randomly generated subdomain---all
of which support HTTPS through a wildcard certificate---or
certain domain aliases like \urll{a0.awsstatic.com}.
CloudFront has a usage tier that is free of charge for a year,
subject to a bandwidth limit of 50 gigabytes per month.

CloudFlare (\url{https://www.cloudflare.com/}),
not to be confused with CloudFront,
is a CDN also marketed as protection against
denial-of-service attacks.
It appears that any domain name on CloudFlare
can front for any other, even custom domains;
however it is not obvious which one is best to use as a front.
The front domain needs to be popular
(causing high collateral damage if blocked),
or else the censor may call our bluff and simply block the domain entirely.
It is doubly bad if that happens because not only is circumvention foiled,
some unsuspecting third part has just had their web site blocked.
A solution may be to round-robin through
a pool of domain names;
or to use ``domainless'' fronting that doesn't send SNI.
Though CloudFlare supports domain fronting,
its terms of service~\cite{cloudflare-terms}
seem to prohibit the kind of tunneled proxying that \meek\ does:
\begin{quote}
\textsc{Section 10: Limitation on non-HTML caching}\\
You acknowledge that CloudFlare's Service is offered as a platform to cache and
serve web pages and websites and is not offered for other purposes
\ldots\ you understand and agree to use the Service solely
for the purpose of hosting and serving web pages\ldots
\end{quote}

Akamai (\url{http://www.akamai.com/}) is a large CDN.
Requests may be fronted through the special domain
\urll{a248.e.akamai.net},
which serves a certificate also good for \urll{*.akamaihd.net}.
The collateral damage of blocking Akamai is enormous:
in 2010 it carried 15--20\% of all web traffic~\cite{akamai}.
Akamai costs more than other CDNs;
it would likely require institutional support
to keep a circumvention system running in the long term.

Microsoft Azure (\url{http://azure.microsoft.com/})
is a cloud computing platform that features a CDN.
Similarly to CloudFront, users get a subdomain
of \urll{vo.msecnd.net},
all of which subdomains can front for each other.
There are other fronting domain names, like \urll{ajax.aspnetcdn.com},
that may offer enough collateral damage.

Fastly (\url{http://www.fastly.com/}) is a CDN.
It is unique among the the services we tested in that
it is the only one that appears to enforce the SNI:
if the SNI and Host do not match,
the Fastly edge server returns an HTTP 400 (``Bad Request'') error.
It is the only service we have found
that requires the ``domainless'' fronting style.

\section{Resistance to traffic analysis}
\label{sec:trafficanalysis}

One of our goals in developing \meek\ is to force
the censor to use relatively expensive statistical classifiers
to effect blocking---generally, to increase the cost of censorship.
We believe \meek\ as described is resistant to the ``easy''
forms of blocking, namely IP address and DNS blocking,
simple pattern-based DPI,
and active probing.
We hope that the censor will have to resort to measuring
more subtle features of the communication like
the packet length distribution and interpacket timing,
or injecting traffic at the risk of causing collateral damage.
In this section we provide a preliminary analysis
of \meek's resistance to such attacks.
Specifically, we consider three traffic features:
packet length distribution,
number of simultaneous connections,
and connection lifetime.

The issue of statistical traffic analysis is a general one~\cite{trafficmorphing},
and mostly orthogonal to \meek's main idea, domain fronting.
It may be that the problem is
best solved by a modular component not
necessarily specifically designed for \meek.

% Advantage is that we are probably proxying web traffic.
As \meek\ is based on HTTPS,
we compare traffic traces of \meek\ against
traces of ``ordinary'' HTTPS traffic.
We did a packet capture
automatically browsing the home pages
of the top 500 Alexa web sites using \meek,
with a firewall in place so that no extraneous traffic was included.
The used \meek\ in Tor Browser,
with the browser camouflage described in Section~\ref{sec:browserextension},
and Google App Engine as the intermediate web service.
The \meek\ trace is 687~megabytes in all
and covers about 4.5 hours of network activity.
Our representative of ordinary HTTPS traffic
is a sanitized trace of 10 minutes of HTTPS traffic
% anon
from Lawrence Berkeley National Laboratory (LBL),
comprising data to and from TCP port 443 on any Google server.
% Mention the non-google if it appears in a figure.
The trace contains packet headers only, not payloads
were replaced by an incrementing counter.
The LBL trace consists 313~megabytes of packet headers,
not payloads, destined for TCP port 443 on any Google server.
The original IP addresses were masked by being
replaced by a counter before we received the trace.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{datalen.pdf}
\caption{
Comparison of TCP payload length distributions
between ordinary HTTPS connections to Google services
from the LBL traffic trace,
and \meek\ running on App Engine, fronted through www.google.com.
% The histogram's bin width is 5~bytes.
}
\label{fig:datalen}
\end{figure}

\subsection{Packet length}
Figure~\ref{fig:datalen}
compares the packet length distribution of both traces in both directions.
Table~\ref{tab:datalen} summarizes the most common values.
In both traces, about 38\% of packets have an empty payload, mostly ACKs.
There is a small peak at the usual TCP Maximum Segment Size
of 1460 bytes.
The concentration of values near 1418 bytes
may be caused by Google servers' sizing of TLS records so they fit within TCP segments.
% https://github.com/joyent/node/issues/6889
% http://mailman.nginx.org/pipermail/nginx-devel/2013-December/004703.html
Conspicuous in the \meek\ trace are a small number of
likely packet sizes,
and the lack of a cluster of small payload lengths of around 50 bytes.
Both of these characteristics are probably artifacts
of Tor's fixed cell size and the nearly fixed-size HTTP headers
added by \meekclient\ and \meekserver.

% Output of datalen.R.
%
% LBL
%          0       1430       1418         41       1416       1460       1260
% 0.37665361 0.09120402 0.08493944 0.06090732 0.03101247 0.02941974 0.02021770
%       1400       1359         33
% 0.01673740 0.01126137 0.01100281
%
% meek
%        1418           0        1460         396         196        1024
% 0.405280243 0.376703906 0.071561089 0.019905460 0.018484996 0.014868083
%         811         783         151        1263
% 0.012312668 0.007811963 0.007031241 0.006569205
\begin{table}[ht]
\normalsize
\centering
\begin{tabular}{r r >{\qquad} r r}
\multicolumn{2}{c}{LBL Google HTTPS} & \multicolumn{2}{>{\qquad}c}{\meek\ on App Engine} \\
0 bytes & 37.6\% & 1418 bytes & 40.5\% \\
1430 bytes & 9.1\% & 0 bytes & 37.7\% \\
1418 bytes & 8.5\% & 1460 bytes & 7.2\% \\
41 bytes & 6.1\% & 396 bytes & 2.0\% \\
1416 bytes & 3.1\% & 196 bytes & 1.8\% \\
1460 bytes & 2.9\% & 1024 bytes & 1.5\%
\end{tabular}
\caption{The most common TCP payload lengths.}
\label{tab:datalen}
\end{table}

% David: I don't think the following paragraph is true.
% Almost all the length>1400 packets are Googleâclient, not clientâGoogle,
% as you can see if you split the histogram up by direction.
%
% To explain the phenomenon, recall that we use browsers to handle HTTPS connections for \meek\ in order
% to hide TLS handshake characteristics.
% Browsers also apply techniques like HTTP pipelining to improve performance. Since \meek\ is always communicating with
% the same Google frontend server, the browser will keep the persistent TLS connection. In addition, small requests 
% can be batched into a large chunk before being sent. This explains why large packets are mostly seen from the trace that
% records \meek's traffic.
% In contrast, normal users may not have persistent connections to Google. For example, a user may search a keyword on
% Google, click a result, and then close the tab that displays search results. The browser may close the 
% connection immediately after the user leaves the Google web page. Next time the user browses Google search, the browser 
% opens a new connection. In this case, small requests do not have such opportunity for batching.

% These browser techniques improve performance, but also pose unexpected consequences. 
% Although \meek\ alters the packet size distribution of underlying Tor traffic, 
% the censor may be aware of the distribution of \meek\ itself. 
% Additionally, the persistent connection itself can be an issue.
% We thus investigated other related characteristics.

\begin{figure}
\centering
\includegraphics[height=\linewidth, angle=270]{figs/connections-google.eps}
\caption{Histogram of each user's connections in the 10-minute window}
\label{fig:connections}
\end{figure}
%add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%(or a blank line to force the subfigure onto a new line)
\begin{figure}
\centering
\includegraphics[width=\linewidth]{figs/conns.eps}
\caption{Concurrent HTTPS connections over time. We measure the trace for the Tor Browser Bundle and Firefox/Chrome extensions.}
\label{fig:conconns}
\end{figure}

\subsection{Concurrent connections}
Figure ~\ref{fig:connections} shows how many HTTPS connections to Google user made
during the 10-minute measurement window.
There are 34,732 connections in total from 2,745 unique IPs. We observe that the majority of users have less than 
50 connections to the Google frontend server, and most of the numbers concentrate on 1--10.

% David: I think this needs to be justified. Leaving Gmail open all day is a common use case,
% as is YouTube, as is finding +1 buttons and Google-source JavaScript on unrelated web sites.
% This is not unexpected
% because a typical pattern of using Google is using the Google search as a stepping stone for other websites.

We measure the number of concurrent HTTPS connections during the automated browsing of Alexa
top 500 sites using three platforms: Tor Browser Bundle, Safari + Firefox extension, and Safari + Chrome extension.
Figure ~\ref{fig:conconns} shows the number over time. We can see that most of the time
the browser has one HTTPS connection to Google. Sometimes the browser may have more than one connection
due to background activities such as statistics reporting. In all cases the number of connections is always 
less than 5. We can conclude that the number of concurrent connections does not show distinct characteristics, as 
a small number of connections can be considered as a normal behavior.

\subsection{Connection lifetime}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{flowduration}
\caption{
CDF of connection lifetime.
The horizontal axis is logarithmic.
meek's connections tend to last longer than those of ordinary HTTPS traffic.
}
\label{fig:duration}
\end{figure}

% Output of flowduration.R.
% LBL
% [1] "42.6%" "87.0%" "92.2%"
% meek
% [1] "10.0%" "30.0%" "40.0%"

We consider the duration of TCP connections as a potential distinguisher.
Figure~\ref{fig:duration} shows the cumulative probability
of connection duration in our two traces.
Considering the LBL trace first,
we see interesting probability concentrations on
some round numbers: 10~s, 60~s, 120~s, 180~s, and 240~s.
We hypothesize that this phenomenon is caused by
keepalive timeouts in web browsers and servers,
and polling behavior of web apps.
The small rise at 600 seconds is an artifact caused
by the fact that the trace is only 10 minutes long.
Connections lasting longer than 10 minutes are not accurately reflected,
however we can say that only about 8\% of connections lasted longer than 10 minutes.

The \meek\ trace shows a propensity for longer connections.
Over 4.5 hours, there were only 10 connections,
three of them lasting for an hour.
The long connections are caused by the client browser extension's
use of long-lived HTTP keepalive connections,
combined with \meekclient's polling requests,
which keep the connection from becoming idle.
The traffic trace represents the browsing of hundreds of web sites
and thousands of HTTPS transactions, but they all
occurred over just a few TCP/TLS connections.
60\% of \meek\ connections lasts five minutes or longer,
while only 13\% of those of ordinary traffic does.
\meek\ has essentially no connections lasting less than 24 seconds,
but such short connections account for over 42\% of the LBL HTTPS connections.
30\% (3 out of 10) of \meek's connections lasted almost exactly one hour,
evidently reflecting a built-in time limit in either the client browser extension
or in App Engine.

The censor may decide to block any long-lived HTTPS connections between
a client and a web service.
According to our traffic trace, doing so will not disrupt more than 8\% of ordinary connections;
whether that is an acceptable cost depends on the censor's
tolerance for collateral damage.
The censor can lower the timing threshold, at the cost of more false positives.
Duration-based blocking is favorable for the circumventor,
because if the censor terminates connections after, say, 10 minutes,
that's 10 minutes of circumvention achieved,
after which \meek\ can start a new connection
and allow Tor to rebuild its circuits.
Future enhancements may even allow reconnecting using the same session ID,
so there will be no effect on the client other than a brief delay
while a new HTTPS connection is established.

% meek is fairly robust against connection termination.
% Well, not really for long-lived TCP connections.
% But it could be.
% Can reconnect and make a new circuit.

\subsection{Conclusion} So far we do not find any obvious traffic characteristics that can be useful for
distinguishing \meek's traffic. But admittedly there two potential weaknesses: long-lived connections 
with bulk data transfer, and deviated distribution of packet sizes. To fundamentally fix these weaknesses 
we need to transform to the traffic into the normal-looking traffic. The problem is inherently difficult, because we need to know \emph{what} is normal traffic, i.e. what is the model of normal traffic, which is an open problem. However, 
the arm-race game is symmetric; since finding a right model is a difficult task for us, it is also difficult for 
the censor. Therefore, the censor can only find ad-hoc features to block forbidden traffic, which are relatively 
easy to defend against. 

\section{Discussion}
\label{sec:discussion}

% Censors that know no bounds: China on Google, Egypt, Pakistan with YouTube.

Domain fronting shares a weakness with decoy routing,
which is that the overt and covert destinations lie on different
network paths.
The difference in paths may create side channels---latency measurements for instance---that
enable the censor to
distinguish fronted traffic from traffic that is truly destined
to the front domain.
For example, a CDN can be expected to have responses
to some fraction of requests already in cache,
and respond to those requests with low latency.
Fronted traffic, on the other hand, always continues all the way
to the origin server after reaching the CDN (as if nothing were ever cached),
resulting in a higher latency.
Latency measurement was applied to decoy routing by Schuhard et~al.~\cite[Section~5]{ccs2012-decoys},
who compared empirical round-trip-time distributions using a
Kolmogorov--Smirnov test.
% time between ChangeCipherSpec and ApplicationData

When domain fronting is combined with Tor,
the CDN or web service effectively becomes
what Tor calls a ``guard node,''
a host with a privileged network position that can observe
the ciphertext entering the network.
One consequence of this fact is that Google (for example)
knows the IP addresses of everyone using the circumvention system,
just as if it were those users' ISP.
Another consequence is that the CDN or web service gets
to observe and correlate both entry and exit traffic,
in the special case where the target of the communication
also lies on the same CDN or web service.
For example, a user fronting through App Engine and
browsing YouTube reveals both their entry and exit traffic to Google,
which may attempt through traffic analysis to determine
which entry packets correspond to which exit packets.
The problem is hard to counter, because the front domain needs
to be a popular destination in order to have high collateral damage,
but popular destinations by definition tend to be visited a lot.
% Possible countermeasure is traffic fingerprinting resistance
% like what mjuarez is working on, mostly orthogonal to circumvention.

We implemented \meek\ as a pluggable transport~\cite{pt} for Tor.
Although it is possible to use the system with proxies other than Tor,
using Tor has some attractive features.
The pluggable transports infrastructure makes it relatively easy to prototype
a circumvention technique and connect it to a global proxy network.
We can treat confidentiality and integrity of tunneled communication
as a problem solved by Tor, which we don't need to solve separately.
Tor's extra proxy hops mean that the HTTP reflector (App Engine)
and the entry bridge do not have to be trusted.

% Edge servers within the censored region.
% Censor could block on the way to the origin server,
% if the censor has visibility to it.
% Maybe the CDN has its own private high-speed cables,
% or it VPNs its own stuff or something.

% Censor could lean on the CDN to block the actual destination internally.

% Firefox plugin uses normal browser trust store.
% Adversary controls CAs. Can MITM and read your tag and block you.
% Maybe not willing to risk getting caught in MITM.
% Could conceivably send cover traffic if MITM detected, but blah.

% \meek\ apart from Tor.
% more risk for the proxy operator
% can require people to run their own proxies Ã  la GoAgent.
% "Censorship implies surveillance"

% Prevalence of no SNI.

\section{Deployment}
\label{sec:deployment}

We implemented \meek\ as a Tor pluggable transport~\cite{pt}
and built experimental releases of the Tor Browser Bundle featuring \meek.
The browser bundle includes Tor and a version of Firefox
called Tor Browser that is patched to defend against application-layer identity leaks.
Users need to download and run the bundle and select \meek\ from the list of transports,
and then a browser window appears,
configured to use \meek\ for circumvention and Tor for anonymity.
We announced our prototype bundles on Tor development mailing lists,
and from there they were picked up by Tor Weekly News on the Tor blog.

\begin{figure}
\includegraphics[width=\linewidth]{clients-meek}
\caption{Concurrent users of \meek\ with Tor.}
\label{fig:clients}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{clients-psiphon3}
\caption{Daily unique users of \meek\ with Psiphon3 (note vertical axis).}
\label{fig:clients}
\end{figure}

Figure~\ref{fig:clients} shows the average number of concurrent users of \meek\ with Tor
since close to the beginning of development,
as reported by the Tor Metrics Portal~\cite{metrics-meek}.
The number of users is estimated by counting the number
of Tor directory requests made by clients~\cite{counting-daily-bridge-users}.
% The drop to zero on May~8 coincides with the reinstallation of the Tor bridge used by \meek.

% Psiphon. Drop in July is due to an unblocking event.
% Different counting method. Client self-reporting of last connection date.

We are running a paid instance of the web app on App Engine for use by the public.
The cost for bandwidth on App Engine is \$0.12 per gigabyte,
with one gigabyte free each day.
The total cost has so far been \$1.11, with bills of
\$0.09 in March,
\$0.73 in April,
and \$0.29 in the first half of May.

\meek\ has a home page at
\url{https://trac.torproject.org/projects/tor/wiki/doc/meek}.
Our source code is in the Git repository at
\url{https://git.torproject.org/pluggable-transports/meek.git}.
As of version 0.5 (May~7, 2014), the source code consists of
about 800 lines of Go for the client programs,
400 lines for \meekserver, and
100 lines for the reflector web app.
Each of the browser extensions
(one for Firefox, one for Chrome)
is about 300 lines of JavaScript.

\subsection{Other deployment scenarios}
\label{sec:otherdeployment}

The deployment we envision and have started to implement
uses a single paid App Engine instance, which is publicly known and usable by anyone.
Client software is configured to use this public instance by default.
A preconfigured public instance has great usability advantages
because there is nothing for the user to upload and nothing to configure.
The number of parties able to analyze users' traffic patterns is somewhat increased:
the path from user to Tor bridge now includes App Engine and the web app operators,
in addition to the ISP and intermediate routers that were there before.
On the other hand, the Tor bridge no longer gets to see users' IP addresses:
all it sees are many connections from App Engine.

Users are also free to upload their own personal copy of the App Engine code, as is done with GoAgent.
App Engine imposes bandwidth quotas on unpaid apps, but they are high enough to allow daily web browsing.
In this scenario, Google still has a privileged network position,
but the user's traffic patterns are no longer visible to the operators of a public app instance.
% Outgoing HTTP requests include app id? As good as an IP address.

% Dreamhost? Other HTTPS webhosts with PHP bridge?

The code that runs on App Engine is very simple.
It just statelessly copies HTTP requests and responses.
Another possible deployment scenario uses a PHP implementation of the reflector,
deployed on an ordinary web hosting service other than App Engine.
In this scenario, domain fronting is not used;
instead unblockability depends on there being many (individually blockable) PHP reflectors.
In other words, it is roughly the same situation as exists today with Tor bridges,
except that it can be much easier for a volunteer to upload a PHP file to a web host
than to set up Tor bridge.
Such PHP bridges could potentially automatically report their own URLs,
which could be distributed using a system like BridgeDB.

% Psiphon idea: use long-polling for downstream data.
% Works with CDNs, not with App Engine.
% Alternative techniques for push-like behavior,
% such as HTTP long polling,
% don't work well with App Engine,
% because App Engine requires requests to finish within 60 seconds.

% App Engine works when appspot.com is blocked but google.com is not.

\section{Future work}
\label{sec:futurework}

In future work we would like to implement pipelining of requests,
so that more than one HTTP request can be outstanding at a time.
This would have better performance compared to the current system,
which serializes requests and responses in order to keep the
underlying TCP stream in order.
A system of sequence numbers and acknowledgments as used in OSS~\cite{oss}
could make this possible.
% Would be useful for Iran-like session cutoff, independent of \meek.

\begin{figure}
\centering
\begin{subfigure}[t]{0.40\linewidth}
\includegraphics[width=\linewidth]{wire-sequential}
\caption{Sequential}
\label{fig:wire-sequential}
\end{subfigure}
\qquad
\begin{subfigure}[t]{0.40\linewidth}
\includegraphics[width=\linewidth]{wire-parallel}
\caption{Parallel}
\label{fig:wire-parallel}
\end{subfigure}

\caption{
The nature of potential performance gain
from sending fronted requests in parallel.
}
\label{fig:wire}
\end{figure}

% Performance measurements
We would like to do more quantitative performance measurements,
in order to measure the overhead in bandwidth and latency that \meek\ has over plain Tor.
We have done informal tests, such as browsing YouTube,
but have not yet put numbers to our measurements.

% Load balancing

% \section*{Acknowledgments}

% We thank Vern Paxson, Nick Weaver, and Doug Tygar for inspiring conversation on this topic.
% Special thanks go to the members of the tor-qa and tor-dev mailing lists
% who responded to our design ideas, reviewed source code, and tested our prototypes.
% Thanks to Psiphon~Inc. for help with design and development, and for providing user count estimates.
% George Kadianakis
% Georg Koppen
% Lunar
% Yawning Angel
% Ox from Lantern.
% Johanna Amann for getting the fraction of SNI from ICSI notary:
%   https://trac.torproject.org/projects/tor/ticket/12208#comment:5
% Arlo Breault (flashproxy-reg-appspot)

%%%%%%%

% HTTPS or not on the App Engine--bridge link.
% HTTPS obscures session ids, equivalent to obscuring TCP connections in other transports.
% Increases latency a lot: \approx 100 ms increased to \approx 350 ms when I tried it in March 2014.

\bibliographystyle{IEEEtran}
\bibliography{meek}

\end{document}
